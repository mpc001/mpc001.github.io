<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0026)https://mpc001.github.io/#home -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <script type="text/javascript" async="" src="indexpics/inpage_linkid.js.download" id="undefined"></script><script type="text/javascript" async="" src="indexpics/ga.js.download"></script><script type="text/javascript" async="" src="indexpics/ga.js.download"></script><script src="indexpics/head.js.download"></script>        <meta name="author" content="Pingchuan Ma">    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Pingchuan Ma is a Postdoctoral Researcher at Meta AI.">
    <meta name="keywords" content="Pingchuan,Pingchuan Ma,Computer,Vision,Machine,Learning,Lipreading,Science,Homepage,Meta">
    <title>Pingchuan Ma</title>

    <link rel="stylesheet" href="indexpics/main.css">
    <script src="indexpics/main.js.download"></script>
    <script src="indexpics/scroll.js.download"></script>
    <script async="" type="text/javascript" src="indexpics/google.js.download"></script>

  <script src="indexpics/google_analytics_auto.js.download"></script></head>

  <body data-new-gr-c-s-check-loaded="14.991.0" data-gr-ext-installed="">

    <div class="outercontainer">
      
      <script src="indexpics/header.js.download"></script><header>  <div class="container header">    <div class="ftheader text"><a href="index.html#home">Pingchuan Ma</a></div>    <div class="ftsubheader text"><a href="index.html#publications">Publications</a></div>    <div class="ftsubheader text"><a href="index.html#home">Home</a></div>  </div></header>
      <div class="container body">

        <div class="content heading anchor" id="home" data-scroll-id="home" tabindex="-1" style="outline: none;">
          <div class="img"><img class="img" length="800px" height='220px' src="pic/ping.png" alt="Photo"></div>
          <div class="text info">
            <h1>Pingchuan Ma</h1>
            <p>
            </p><div>AI Research Scientist</div>
            <div>Meta</div>
            <div>Email:&nbsp;pingchuanma [at] meta (dot) com</div>
            <p>
            <span><a href="https://scholar.google.com/citations?user=ZUW256sAAAAJ&hl=en">Google Scholar</a></span> / 
            <span class="tag"><a href="https://github.com/mpc001">Github</a></span>
            </p><p>
          </p></div>
        
          
          <div class="text">
            <p>I am an AI Research Scientist at Meta.</a>
            	
            Before joining Meta in 2021, I received my Ph.D. degree and M.Sc. degree from Impeiral College London in 2022 and 2017, where I was supervised by Prof. Maja Pantic and Dr. Stavros Petridis. I also obtained my B.Sc. degree from Beihang University in 2015.

            My research lies in the areas of computer vision and speech processing, aiming at understanding human behaviours with machine intelligence. My research currently focuses on deep learning models for audiovisual fusion and visual speech recognition / lipreading.
            </p>


          </div>
        </div>


        <div class="content anchor" id="publications">
          <div class="text" style="z-index:1;position:relative">
            <h3 style="margin-bottom:0em">
              Publications 
                (<a href="index.html" id="select0" onclick="showPubs(0); return false;" style="text-decoration: underline; color: rgb(0, 0, 0);">show selected</a> / 
                <a href="index.html" id="select1" onclick="showPubs(1); return false;" style="">show all by date</a>)
            </h3>
          </div>
          

          <div id="pubs">

          </div>


          <script id="pubs_selected" language="text">
            
            <div class="text anchor">&nbsp;</div>


      <div class="publication">
              <div class="img"><img class="img" src="pics/2023icassp_autoavsr.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2303.14307">Auto-AVSR: Audio-Visual Speech Recognition with Automatic Labels</a></div>
                <div class="authors">
                  <span class="author jw">Pingchuan Ma</a></span>,
                  <span class="author">Alexandros Haliassos</a></span>,
                  <span class="author">Adriana Fernandez-Lopez</a></span>,
                  <span class="author">Honglie Chen</a></span>,
                  <span class="author">Stavros Petridis</a></span>,
                  <span class="author">Maja Pantic</a></span>
                </div>
                <div>   
                  IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2023</a></span> 
                </div>
                <div>
                  [<span class="highlight"><a href="https://github.com/mpc001/auto_avsr">Code/Models</a></span>]
                </div>
              </div>
      </div>

      <div class="publication"> 
              <div class="img"><img class="img" src="pics/2023iclr_raven.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2212.06246">Jointly Learning Visual and Auditory Speech Representations from Raw Data</a></div>
                <div class="authors">
                  <span class="author">Alexandros Haliassos</a></span>,
                  <span class="author jw">Pingchuan Ma</a></span>,
                  <span class="author">Rodrigo Mira</a></span>,
                  <span class="author">Stavros Petridis</a></span>,
                  <span class="author">Maja Pantic</a></span>
                </div>
                <div>   
                  International Conference on Learning Representations (<b>ICLR</b>), 2023</a></span> 
                </div>
                <div>
                  [<span class="highlight"><a href="https://github.com/ahaliassos/raven">Code/Models</a></span>]
                </div>
              </div>
      </div>


      <div class="publication"> 
              <div class="img"><img class="img" src="pics/2022nature_visual.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2202.13084">Visual Speech Recognition for Multiple Languages in the Wild</a></div>
                <div class="authors">
                  <span class="author jw">Pingchuan Ma</a></span>,
                  <span class="author">Stavros Petridis</a></span>,
                  <span class="author">Maja Pantic</a></span>
                </div>
                <div>   
                  Nature Machine Intelligence (<b>Nature ML</b>), 2022</a></span> 
                </div>
                <div>
                  [<span class="highlight"><a href="https://github.com/mpc001/Visual_Speech_Recognition_for_Multiple_Languages">Code/Models</a></span>]
                </div>
              </div>
      </div>

      <div class="publication"> 
              <div class="img"><img class="img" src="pics/2022icassp_training.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2209.01383">Training Strategies for Improved Lip-Reading</a></div>
                <div class="authors">
                  <span class="author jw">Pingchuan Ma</a></span>,
                  <span class="author">Yujiang Wang</a></span>,
                  <span class="author">Stavros Petridis</a></span>,
                  <span class="author">Jie Shen</a></span>,
                  <span class="author">Maja Pantic</a></span>
                </div>
                <div>   
                  IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2022</a></span> 
                </div>
                <div>
                  [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                </div>
              </div>
      </div>


      <div class="publication"> 
              <div class="img"><img class="img" src="pics/2021icassp_conformer.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2102.06657">End-to-End Audio-visual Speech Recognition with Conformers</a></div>
                <div class="authors">
                  <span class="author jw">Pingchuan Ma</a></span>,
                  <span class="author">Stavros Petridis</a></span>,
                  <span class="author">Maja Pantic</a></span>
                </div>
                <div>   
                  IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2021</a></span> 
                </div>
                <div>
                  [<span class="highlight"><a href="https://github.com/mpc001/auto_avsr">Code/Models</a></span>]
                </div>
              </div>
      </div>


      <div class="publication"> 
              <div class="img"><img class="img" src="pics/2020icassp_tcn.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="papers/2023TMI-XDing.pdf">Lipreading Using Temporal Convolutional Networks</a></div>
                <div class="authors">
                  <span class="author">Brais Martinez</a></span>,
                  <span class="author jw">Pingchuan Ma</a></span>,
                  <span class="author">Stavros Petridis</a></span>,
                  <span class="author">Maja Pantic</a></span>
                </div>
                <div>   
                  IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2020</a></span> 
                </div>
                <div>
                  [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                </div>
              </div>
      </div>


      <div class="publication"> 
              <div class="img"><img class="img" src="pics/2018icassp_avsr.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="papers/2023TMI-XDing.pdf">End-to-end Audio-visual Speech Recognition</a></div>
                <div class="authors">
                  <span class="author">Stavros Petridis</a></span>,
                  <span class="author">Themos Stafylakis</a></span>,
                  <span class="author jw">Pingchuan Ma</a></span>,
                  <span class="author">Georgios Tzimiropoulos</a></span>,
                  <span class="author">Maja Pantic</a></span>
                </div>
                <div>   
                  IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2018</a></span> 
                </div>
                <div>
                  [<span class="highlight"><a href="https://github.com/mpc001/end-to-end-lipreading">Code/Models</a></span>]
                </div>
              </div>
      </div>

          </script>    


          
          <script id="pubs_by_date" language="text">

      <div class="text anchor"><h4>2023 (7)</h4></div>


          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023interspeech_streaming.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2211.02133">Streaming Audio-Visual Speech Recognition with Alignment Regularization</a></div>
                    <div class="authors">
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Niko Moritz</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Christian Fuegen</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      Conference of the International Speech Communication Association (<b>INTERSPEECH</b>), 2023</a></span> 
                    </div>
                  </div>
          </div>


          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023interspeech_sparse.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2307.04552">SparseVSR: Lightweight and Noise Robust Visual Speech Recognition</a></div>
                    <div class="authors">
                      <span class="author">Adriana Fernandez-Lopez</a></span>,
                      <span class="author">Honglie Chen</a></span>,
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Alexandros Haliassos</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>
                      Conference of the International Speech Communication Association (<b>INTERSPEECH</b>), 2023</a></span>
                    </div>
                  </div>
          </div>


          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023cvpr_synthvsr.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2303.17200">SynthVSR: Scaling Up Visual Speech Recognition With Synthetic Supervision</a></div>
                    <div class="authors">
                      <span class="author">Xubo Liu</a></span>,
                      <span class="author">Egor Lakomkin</a></span>,
                      <span class="author">Konstantinos Vougioukas</a></span>,
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Honglie Chen</a></span>,
                      <span class="author">Ruiming Xie</a></span>,
                      <span class="author">Morrie Doulaty</a></span>,
                      <span class="author">Niko Moritz</a></span>,
                      <span class="author">Jáchym Kolář</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023</a></span> 
                    </div>
                  </div>
          </div>


          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023icassp_autoavsr.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2303.14307">Auto-AVSR: Audio-Visual Speech Recognition with Automatic Labels</a></div>
                    <div class="authors">
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Alexandros Haliassos</a></span>,
                      <span class="author">Adriana Fernandez-Lopez</a></span>,
                      <span class="author">Honglie Chen</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2023</a></span> 
                    </div>
                    <div>
                      [<span class="highlight"><a href="https://github.com/mpc001/auto_avsr">Code/Models</a></span>]
                    </div>
                  </div>
          </div>


          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023icassp_multiple.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2303.09455">Learning Cross-lingual Visual Speech Representations</a></div>
                    <div class="authors">
                      <span class="author">Andreas Zinonos</a></span>,
                      <span class="author">Alexandros Haliassos</a></span>,
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2023</a></span> 
                    </div>
                  </div>
          </div>


          <div class="publication"> 
                  <div class="img"><img class="img" src="pics/2023iclr_raven.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2212.06246">Jointly Learning Visual and Auditory Speech Representations from Raw Data</a></div>
                    <div class="authors">
                      <span class="author">Alexandros Haliassos</a></span>,
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Rodrigo Mira</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      International Conference on Learning Representations (<b>ICLR</b>), 2023</a></span> 
                    </div>
                    <div>
                      [<span class="highlight"><a href="https://github.com/ahaliassos/raven">Code/Models</a></span>]
                    </div>
                  </div>
          </div>

          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023tpami_ssl.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2203.13166">Self-supervised Video-centralised Transformer for Video Face Clustering</a></div>
                    <div class="authors">
                      <span class="author">Yujiang Wang</a></span>,
                      <span class="author">Mingzhi Dong</a></span>,
                      <span class="author">Jie Shen</a></span>,
                      <span class="author">Yiming Luo</a></span>,
                      <span class="author">Yiming Lin</a></span>,
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2023</a></span> 
                    </div>
                  </div>
          </div>

           
            <div class="text anchor"><h4>2022 (4)</h4></div>   

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2022nature_visual.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2202.13084">Visual Speech Recognition for Multiple Languages in the Wild</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Nature Machine Intelligence (<b>Nature ML</b>), 2022</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/Visual_Speech_Recognition_for_Multiple_Languages">Code/Models</a></span>]
                          </div>
                        </div>
                </div>


                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2022icassp_training.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2209.01383">Training Strategies for Improved Lip-Reading</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Yujiang Wang</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Jie Shen</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2022</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                          </div>
                        </div>
                </div>


                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2022cybernetics_v2a.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2104.13332">End-to-End Video-To-Speech Synthesis using Generative Adversarial Networks</a></div>
                          <div class="authors">
                            <span class="author">Rodrigo Mira</a></span>,
                            <span class="author">Konstantinos Vougioukas</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Björn W. Schuller</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE Transactions on Cybernetics, 2022</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2022frontiers_animation.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://www.frontiersin.org/articles/10.3389/fnins.2021.781196">Speech-driven Facial Animations Improve Speech-in-Noise Comprehension of Humans</a></div>
                          <div class="authors">
                            <span class="author">Enrico Varano</a></span>,
                            <span class="author">Konstantinos Vougioukas</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>,
                            <span class="author">Tobias Reichenbach</a></span>

                          </div>
                          <div>   
                            Frontiers in Neuroscience, 2022</a></span> 
                          </div>
                        </div>
                </div>



            <div class="text anchor"><h4>2021 (5)</h4></div>   

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2021interspeech_lira.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2106.09171">LiRA: Learning Visual Speech Representations from Audio through Self-supervision</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma*</a></span>,
                            <span class="author">Rodrigo Mira*</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Björn W. Schuller</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Conference of the International Speech Communication Association (<b>INTERSPEECH</b>), 2021</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication">
                        <div class="img"><img class="img" src="pics/2021icassp_towards.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2007.06504">Towards Practical Lipreading with Distilled and Efficient Models</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma*</a></span>,
                            <span class="author">Brais Martinez*</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2021</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2021icassp_conformer.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2102.06657">End-to-End Audio-visual Speech Recognition with Conformers</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2021</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/auto_avsr">Code/Models</a></span>]
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2021icassp_detecting.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1912.08639">Detecting Adversarial Attacks on Audio-visual Speech Recognition</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2021</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2021wacv_dctcn.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2009.14233">Lip-reading with Densely Connected Temporal Convolutional Networks</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma*</a></span>,
                            <span class="author">Yujiang Wang*</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Jie Shen</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2021</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                          </div>
                        </div>
                </div>

            <div class="text anchor"><h4>2020 (4)</h4></div>   
                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2020icassp_pose2.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1911.06095">Towards Pose-invariant Lip-Reading</a></div>
                          <div class="authors">
                            <span class="author">Shiyang Cheng*</a></span>,
                            <span class="author jw">Pingchuan Ma*</a></span>,
                            <span class="author">Georgios Tzimiropoulos</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Adrian Bulat</a></span>,
                            <span class="author">Jie Shen</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2020</a></span> 
                          </div>
                        </div>
                </div>


                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2020icassp_tcn.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2001.08702">Lipreading Using Temporal Convolutional Networks</a></div>
                          <div class="authors">
                            <span class="author">Brais Martinez</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2020</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2020icassp_ssl.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2001.04316">Visually Guided Self-Supervised Learning of Speech Representations</a></div>
                          <div class="authors">
                            <span class="author">Abhinav Shukla</a></span>,
                            <span class="author">Konstantinos Vougioukas</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2020</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2020prl_small.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1904.01954">End-to-End Visual Speech Recognition for Small-Scale Datasets</a></div>
                          <div class="authors">
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Yujiang Wang</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Zuwei Li</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Pattern Recognition Letters, 2020</a></span> 
                          </div>
                        </div>
                </div>


            <div class="text anchor"><h4>2019 (2)</h4></div>
            
                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2019interspeech_lombard.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1906.02112">Investigating the Lombard Effect Influence on End-to-End Audio-Visual Speech Recognition</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Conference of the International Speech Communication Association (<b>INTERSPEECH</b>), 2019</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2019interspeech_animation.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1906.06301">Video-Driven Speech Reconstruction using Generative Adversarial Networks</a></div>
                          <div class="authors">
                            <span class="author">Konstantinos Vougioukas</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Conference of the International Speech Communication Association (<b>INTERSPEECH</b>), 2019</a></span> 
                          </div>
                        </div>
                </div>


            <div class="text anchor"><h4>2018 (2)</h4></div>

                <div class="publication">
                        <div class="img"><img class="img" src="pics/2018slt_hybrid.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1810.00108">Audio-visual Speech Recognition with a Hybrid CTC/Attention Architecture</a></div>
                          <div class="authors">
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Themos Stafylakis</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Georgios Tzimiropoulos</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Spoken Language Technology Workshop (<b>SLT</b>), 2018</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2018icassp_avsr.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1802.06424">End-to-end Audio-visual Speech Recognition</a></div>
                          <div class="authors">
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Themos Stafylakis</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Georgios Tzimiropoulos</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2018</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/end-to-end-lipreading">Code/Models</a></span>]
                          </div>
                        </div>
                </div>


          <div class="text anchor"><h4>2016 (1)</h4></div>

            <div class="publication"> 
                    <div class="img"><img class="img" src="pics/2016infomration_rotated.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                    <div class="text">
                      <div class="venue"><a name="jenga_scirobot" href="https://link.springer.com/article/10.1007/s11432-015-5372-0">Rotated Neighbor Learning-Based Auto-Configured Evolutionary Algorithm</a></div>
                      <div class="authors">
                        <span class="author">Yuanjun Laili</a></span>,
                        <span class="author">Lin Zhang</a></span>,
                        <span class="author">Fei Tao</a></span>,
                        <span class="author jw">Pingchuan Ma</a></span>
                      </div>
                      <div>   
                        Science China Information Sciences, 2016</a></span> 
                      </div>
                    </div>
            </div>  


          </script>


        </div>  <!-- content -->

      </div> <!-- container -->
    </div> <!-- outer container -->

    <script>showPubs(0);</script>
    <script>var scroll = new SmoothScroll('a[href*="#"]', {speed: 1000});</script>

  

<div id="footer">
  <div id="footer-text"></div>
</div>
  <p><center>


  </div>        
  <br>
     
  </center></p>
</div>


</body><div id="__genieContainer" style="all: initial;"></div></html>
