<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0026)https://mpc001.github.io/#home -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <script type="text/javascript" async="" src="indexpics/inpage_linkid.js.download" id="undefined"></script><script type="text/javascript" async="" src="indexpics/ga.js.download"></script><script type="text/javascript" async="" src="indexpics/ga.js.download"></script><script src="indexpics/head.js.download"></script>        <meta name="author" content="Pingchuan Ma">    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Pingchuan Ma is a Postdoctoral Researcher at Meta AI.">
    <meta name="keywords" content="Pingchuan,Pingchuan Ma,Computer,Vision,Machine,Learning,Lipreading,Science,Homepage,Meta">
    <title>Pingchuan Ma</title>

    <link rel="stylesheet" href="indexpics/main.css">
    <script src="indexpics/main.js.download"></script>
    <script src="indexpics/scroll.js.download"></script>
    <script async="" type="text/javascript" src="indexpics/google.js.download"></script>

  <script src="indexpics/google_analytics_auto.js.download"></script></head>

  <body data-new-gr-c-s-check-loaded="14.991.0" data-gr-ext-installed="">

    <div class="outercontainer">
      
      <script src="indexpics/header.js.download"></script><header>  <div class="container header">    <div class="ftheader text"><a href="index.html#home">Pingchuan Ma</a></div>    <div class="ftsubheader text"><a href="index.html#publications">Publications</a></div>    <div class="ftsubheader text"><a href="index.html#home">Home</a></div>  </div></header>
      <div class="container body">

        <div class="content heading anchor" id="home" data-scroll-id="home" tabindex="-1" style="outline: none;">
          <div class="img"><img class="img" length="800px" height='220px' src="pic/ping.png" alt="Photo"></div>
          <div class="text info">
            <h1>Pingchuan Ma</h1>
            <p>
            </p><div>Postdoctoral Researcher</div>
            <div>Meta AI</div>
            <div>Email:&nbsp;pingchuanma [at] meta (dot) com</div>
            <p>
            <span><a href="https://scholar.google.com/citations?user=ZUW256sAAAAJ&hl=en">Google Scholar</a></span> / 
            <span class="tag"><a href="https://github.com/mpc001">Github</a></span>
            </p><p>
          </p></div>
        
          
          <div class="text">
            <p>I am a postdoctoral researcher of <a href="https://about.meta.com/uk/realitylabs/">Reality Labs</a> at <a href="https://ai.facebook.com">Meta AI</a>. 
            	
            Before joining Meta, I obtained my Ph.D. degree at <a href="https://www.imperial.ac.uk">Impeiral College London</a>, supervised by Prof. <a href="https://ibug.doc.ic.ac.uk/people/mpantic">Maja Pantic</a> and Dr. <a href="https://ibug.doc.ic.ac.uk/people/spetridis">Stavros Petridis</a>. I obtained my M.Sc. degree in Machine Learning at Department of Computing from Imperial College London and B.Sc. degree at School of Automation Science and Electrical Engineering at <a href="https://ev.buaa.edu.cn">Beihang University</a> supervised by Prof. <a href="https://scholar.google.com/citations?user=-LQGKncAAAAJ&hl=en">Fei Tao</a>.

            My research lies in the areas of artificial intelligence, computer vision and speech processing, aiming at understanding human behaviours with machine intelligence. Specifically, I work on deep learning models for audiovisual fusion, visual speech recognition / lipreading.
            </p>


          </div>
        </div>


        <div class="content anchor" id="publications">
          <div class="text" style="z-index:1;position:relative">
            <h3 style="margin-bottom:0em">
              Publications 
                (<a href="index.html" id="select0" onclick="showPubs(0); return false;" style="text-decoration: underline; color: rgb(0, 0, 0);">show selected</a> / 
                <a href="index.html" id="select1" onclick="showPubs(1); return false;" style="">show all by date</a>)
            </h3>
          </div>
          

          <div id="pubs">

          </div>


          <script id="pubs_selected" language="text">
            
            <div class="text anchor">&nbsp;</div>


      <div class="publication">
              <div class="img"><img class="img" src="pics/2023icassp_autoavsr.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2303.14307">Auto-AVSR: Audio-Visual Speech Recognition with Automatic Labels</a></div>
                <div class="authors">
                  <span class="author jw">Pingchuan Ma</a></span>,
                  <span class="author">Alexandros Haliassos</a></span>,
                  <span class="author">Adriana Fernandez-Lopez</a></span>,
                  <span class="author">Honglie Chen</a></span>,
                  <span class="author">Stavros Petridis</a></span>,
                  <span class="author">Maja Pantic</a></span>
                </div>
                <div>   
                  IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2023</a></span> 
                </div>
                <div>
                  [<span class="highlight"><a href="https://github.com/mpc001/auto_avsr">Code/Models</a></span>]
                </div>
              </div>
      </div>


      <div class="publication"> 
              <div class="img"><img class="img" src="pics/2022nature_visual.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2202.13084">Visual Speech Recognition for Multiple Languages in the Wild</a></div>
                <div class="authors">
                  <span class="author jw">Pingchuan Ma</a></span>,
                  <span class="author">Stavros Petridis</a></span>,
                  <span class="author">Maja Pantic</a></span>
                </div>
                <div>   
                  Nature Machine Intelligence (<b>Nature ML</b>), 2022</a></span> 
                </div>
                <div>
                  [<span class="highlight"><a href="https://github.com/mpc001/Visual_Speech_Recognition_for_Multiple_Languages">Code/Models</a></span>]
                </div>
              </div>
      </div>

      <div class="publication"> 
              <div class="img"><img class="img" src="pics/2022icassp_training.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2209.01383">Training Strategies for Improved Lip-Reading</a></div>
                <div class="authors">
                  <span class="author jw">Pingchuan Ma</a></span>,
                  <span class="author">Yujiang Wang</a></span>,
                  <span class="author">Stavros Petridis</a></span>,
                  <span class="author">Jie Shen</a></span>,
                  <span class="author">Maja Pantic</a></span>
                </div>
                <div>   
                  IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2022</a></span> 
                </div>
                <div>
                  [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                </div>
              </div>
      </div>


      <div class="publication"> 
              <div class="img"><img class="img" src="pics/2021icassp_conformer.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2102.06657">End-to-End Audio-visual Speech Recognition with Conformers</a></div>
                <div class="authors">
                  <span class="author jw">Pingchuan Ma</a></span>,
                  <span class="author">Stavros Petridis</a></span>,
                  <span class="author">Maja Pantic</a></span>
                </div>
                <div>   
                  IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2021</a></span> 
                </div>
                <div>
                  [<span class="highlight"><a href="https://github.com/mpc001/auto_avsr">Code/Models</a></span>]
                </div>
              </div>
      </div>



      <div class="publication"> 
              <div class="img"><img class="img" src="pics/2020icassp_tcn.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="papers/2023TMI-XDing.pdf">Lipreading Using Temporal Convolutional Networks</a></div>
                <div class="authors">
                  <span class="author">Brais Martinez</a></span>,
                  <span class="author jw">Pingchuan Ma</a></span>,
                  <span class="author">Stavros Petridis</a></span>,
                  <span class="author">Maja Pantic</a></span>
                </div>
                <div>   
                  IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2020</a></span> 
                </div>
                <div>
                  [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                </div>
              </div>
      </div>


      <div class="publication"> 
              <div class="img"><img class="img" src="pics/2018icassp_avsr.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="papers/2023TMI-XDing.pdf">End-to-end Audio-visual Speech Recognition</a></div>
                <div class="authors">
                  <span class="author">Stavros Petridis</a></span>,
                  <span class="author">Themos Stafylakis</a></span>,
                  <span class="author jw">Pingchuan Ma</a></span>,
                  <span class="author">Georgios Tzimiropoulos</a></span>,
                  <span class="author">Maja Pantic</a></span>
                </div>
                <div>   
                  IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2018</a></span> 
                </div>
                <div>
                  [<span class="highlight"><a href="https://github.com/mpc001/end-to-end-lipreading">Code/Models</a></span>]
                </div>
              </div>
      </div>

          </script>    


          
          <script id="pubs_by_date" language="text">

      <div class="text anchor"><h4>2023 (6)</h4></div>   


          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023interspeech_streaming.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2211.02133">Streaming Audio-Visual Speech Recognition with Alignment Regularization</a></div>
                    <div class="authors">
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Niko Moritz</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Christian Fuegen</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      Conference of the International Speech Communication Association (<b>INTERSPEECH</b>), 2023</a></span> 
                    </div>
                  </div>
          </div>


          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023cvpr_synthvsr.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2303.17200">SynthVSR: Scaling Up Visual Speech Recognition With Synthetic Supervision</a></div>
                    <div class="authors">
                      <span class="author">Xubo Liu</a></span>,
                      <span class="author">Egor Lakomkin</a></span>,
                      <span class="author">Konstantinos Vougioukas</a></span>,
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Honglie Chen</a></span>,
                      <span class="author">Ruiming Xie</a></span>,
                      <span class="author">Morrie Doulaty</a></span>,
                      <span class="author">Niko Moritz</a></span>,
                      <span class="author">Jáchym Kolář</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023</a></span> 
                    </div>
                  </div>
          </div>

          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023icassp_autoavsr.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2303.14307">Auto-AVSR: Audio-Visual Speech Recognition with Automatic Labels</a></div>
                    <div class="authors">
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Alexandros Haliassos</a></span>,
                      <span class="author">Adriana Fernandez-Lopez</a></span>,
                      <span class="author">Honglie Chen</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2023</a></span> 
                    </div>
                    <div>
                      [<span class="highlight"><a href="https://github.com/mpc001/auto_avsr">Code/Models</a></span>]
                    </div>
                  </div>
          </div>

          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023icassp_multiple.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2303.09455">Learning Cross-lingual Visual Speech Representations</a></div>
                    <div class="authors">
                      <span class="author">Andreas Zinonos</a></span>,
                      <span class="author">Alexandros Haliassos</a></span>,
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2023</a></span> 
                    </div>
                  </div>
          </div>


          <div class="publication"> 
                  <div class="img"><img class="img" src="pics/2023iclr_raven.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2212.06246">Jointly Learning Visual and Auditory Speech Representations from Raw Data</a></div>
                    <div class="authors">
                      <span class="author">Alexandros Haliassos</a></span>,
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Rodrigo Mira</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      International Conference on Learning Representations (<b>ICLR</b>), 2023</a></span> 
                    </div>
                    <div>
                      [<span class="highlight"><a href="https://github.com/ahaliassos/raven">Code/Models</a></span>]
                    </div>
                  </div>
          </div>

          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023tpami_ssl.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2203.13166">Self-supervised Video-centralised Transformer for Video Face Clustering</a></div>
                    <div class="authors">
                      <span class="author">Yujiang Wang</a></span>,
                      <span class="author">Mingzhi Dong</a></span>,
                      <span class="author">Jie Shen</a></span>,
                      <span class="author">Yiming Luo</a></span>,
                      <span class="author">Yiming Lin</a></span>,
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2023</a></span> 
                    </div>
                  </div>
          </div>

           
            <div class="text anchor"><h4>2022 (4)</h4></div>   

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2022nature_visual.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2202.13084">Visual Speech Recognition for Multiple Languages in the Wild</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Nature Machine Intelligence (<b>Nature ML</b>), 2022</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/Visual_Speech_Recognition_for_Multiple_Languages">Code/Models</a></span>]
                          </div>
                        </div>
                </div>


                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2022icassp_training.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2209.01383">Training Strategies for Improved Lip-Reading</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Yujiang Wang</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Jie Shen</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2022</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                          </div>
                        </div>
                </div>


                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2022cybernetics_v2a.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2104.13332">End-to-End Video-To-Speech Synthesis using Generative Adversarial Networks</a></div>
                          <div class="authors">
                            <span class="author">Rodrigo Mira</a></span>,
                            <span class="author">Konstantinos Vougioukas</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Björn W. Schuller</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE Transactions on Cybernetics, 2022</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2022frontiers_animation.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://www.frontiersin.org/articles/10.3389/fnins.2021.781196">Speech-driven Facial Animations Improve Speech-in-Noise Comprehension of Humans</a></div>
                          <div class="authors">
                            <span class="author">Enrico Varano</a></span>,
                            <span class="author">Konstantinos Vougioukas</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>,
                            <span class="author">Tobias Reichenbach</a></span>

                          </div>
                          <div>   
                            Frontiers in Neuroscience, 2022</a></span> 
                          </div>
                        </div>
                </div>



            <div class="text anchor"><h4>2021 (5)</h4></div>   

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2021interspeech_lira.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2106.09171">LiRA: Learning Visual Speech Representations from Audio through Self-supervision</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma*</a></span>,
                            <span class="author">Rodrigo Mira*</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Björn W. Schuller</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Conference of the International Speech Communication Association (<b>INTERSPEECH</b>), 2021</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication">
                        <div class="img"><img class="img" src="pics/2021icassp_towards.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2007.06504">Towards Practical Lipreading with Distilled and Efficient Models</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma*</a></span>,
                            <span class="author">Brais Martinez*</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2021</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2021icassp_conformer.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2102.06657">End-to-End Audio-visual Speech Recognition with Conformers</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2021</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/auto_avsr">Code/Models</a></span>]
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2021icassp_detecting.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1912.08639">Detecting Adversarial Attacks on Audio-visual Speech Recognition</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2021</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2021wacv_dctcn.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2009.14233">Lip-reading with Densely Connected Temporal Convolutional Networks</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma*</a></span>,
                            <span class="author">Yujiang Wang*</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Jie Shen</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2021</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                          </div>
                        </div>
                </div>

            <div class="text anchor"><h4>2020 (4)</h4></div>   
                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2020icassp_pose2.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1911.06095">Towards Pose-invariant Lip-Reading</a></div>
                          <div class="authors">
                            <span class="author">Shiyang Cheng*</a></span>,
                            <span class="author jw">Pingchuan Ma*</a></span>,
                            <span class="author">Georgios Tzimiropoulos</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Adrian Bulat</a></span>,
                            <span class="author">Jie Shen</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2020</a></span> 
                          </div>
                        </div>
                </div>


                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2020icassp_tcn.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2001.08702">Lipreading Using Temporal Convolutional Networks</a></div>
                          <div class="authors">
                            <span class="author">Brais Martinez</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2020</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2020icassp_ssl.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2001.04316">Visually Guided Self-Supervised Learning of Speech Representations</a></div>
                          <div class="authors">
                            <span class="author">Abhinav Shukla</a></span>,
                            <span class="author">Konstantinos Vougioukas</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2020</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2020prl_small.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1904.01954">End-to-End Visual Speech Recognition for Small-Scale Datasets</a></div>
                          <div class="authors">
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Yujiang Wang</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Zuwei Li</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Pattern Recognition Letters, 2020</a></span> 
                          </div>
                        </div>
                </div>


            <div class="text anchor"><h4>2019 (2)</h4></div>
            
                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2019interspeech_lombard.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1906.02112">Investigating the Lombard Effect Influence on End-to-End Audio-Visual Speech Recognition</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Conference of the International Speech Communication Association (<b>INTERSPEECH</b>), 2019</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2019interspeech_animation.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1906.06301">Video-Driven Speech Reconstruction using Generative Adversarial Networks</a></div>
                          <div class="authors">
                            <span class="author">Konstantinos Vougioukas</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Conference of the International Speech Communication Association (<b>INTERSPEECH</b>), 2019</a></span> 
                          </div>
                        </div>
                </div>


            <div class="text anchor"><h4>2018 (2)</h4></div>

                <div class="publication">
                        <div class="img"><img class="img" src="pics/2018slt_hybrid.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1810.00108">Audio-visual Speech Recognition with a Hybrid CTC/Attention Architecture</a></div>
                          <div class="authors">
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Themos Stafylakis</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Georgios Tzimiropoulos</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Spoken Language Technology Workshop (<b>SLT</b>), 2018</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2018icassp_avsr.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1802.06424">End-to-end Audio-visual Speech Recognition</a></div>
                          <div class="authors">
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Themos Stafylakis</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Georgios Tzimiropoulos</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2018</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/end-to-end-lipreading">Code/Models</a></span>]
                          </div>
                        </div>
                </div>


          <div class="text anchor"><h4>2016 (1)</h4></div>

            <div class="publication"> 
                    <div class="img"><img class="img" src="pics/2016infomration_rotated.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                    <div class="text">
                      <div class="venue"><a name="jenga_scirobot" href="https://link.springer.com/article/10.1007/s11432-015-5372-0">Rotated Neighbor Learning-Based Auto-Configured Evolutionary Algorithm</a></div>
                      <div class="authors">
                        <span class="author">Yuanjun Laili</a></span>,
                        <span class="author">Lin Zhang</a></span>,
                        <span class="author">Fei Tao</a></span>,
                        <span class="author jw">Pingchuan Ma</a></span>
                      </div>
                      <div>   
                        Science China Information Sciences, 2016</a></span> 
                      </div>
                    </div>
            </div>  


          </script>


        </div>  <!-- content -->

      </div> <!-- container -->
    </div> <!-- outer container -->

    <script>showPubs(0);</script>
    <script>var scroll = new SmoothScroll('a[href*="#"]', {speed: 1000});</script>

  

<div id="footer">
  <div id="footer-text"></div>
</div>
  <p><center>


  </div>        
  <br>
     
  </center></p>
</div>


</body><div id="__genieContainer" style="all: initial;"></div></html>